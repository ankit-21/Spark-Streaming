{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"C:/Java/jdk1.8.0_261\"\n",
    "os.environ[\"SPARK_HOME\"] = \"D:/Spark/spark-3.0.1-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credential for Twitter Developer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = 'ACCESS_TOKEN'\n",
    "ACCESS_SECRET = 'ACCESS_SECRET'\n",
    "CONSUMER_KEY = 'CONSUMER_KEY'\n",
    "CONSUMER_SECRET = 'CONSUMER_SECRET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authorizing tweepy with credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the dataframe to store the incoming tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Tweets', 'tweet_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to store the tweet stream in the defined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream(data, file_name):\n",
    "    i = 0\n",
    "    for tweet in tweepy.Cursor(api.search, q=data, count=100, lang='en').items():\n",
    "        print(i, end='\\r')\n",
    "        df.loc[i, 'Tweets'] = tweet.text\n",
    "        df.loc[i, 'tweet_date'] = tweet.created_at\n",
    "        df.to_excel('{}.xlsx'.format(file_name))\n",
    "        i+=1\n",
    "        if i == 1200:\n",
    "            break\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start streaming tweets and storing in the defined dataframe, save locally in a file named Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199\r"
     ]
    }
   ],
   "source": [
    "stream(data = ['#hospital'], file_name = 'Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the stored file and performed some data cleaning on the stored tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @WorldofAnimal1: üêæBeautiful Olive!!‚ù§\\n#dogs...</td>\n",
       "      <td>2020-10-20 17:27:57</td>\n",
       "      <td>rt beautiful olive dogsoftwitter doglover vete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @WorldofAnimal1: üêæMeet Gorgeous Sam!!üòÉ\\n#Ca...</td>\n",
       "      <td>2020-10-20 17:27:52</td>\n",
       "      <td>rt meet gorgeous sam catsontwitter catsoftwitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Injured \\n\\n#spooktober #digitalart #digitalil...</td>\n",
       "      <td>2020-10-20 17:19:35</td>\n",
       "      <td>injured spooktober digitalart digitalillustrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This video gives a high-level introduction to ...</td>\n",
       "      <td>2020-10-20 17:15:03</td>\n",
       "      <td>this video gives a high level introduction to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @WilliamsRef: Take a look at our pharmacy c...</td>\n",
       "      <td>2020-10-20 17:12:00</td>\n",
       "      <td>rt take a look at our pharmacy coldroom with b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets          tweet_date  \\\n",
       "0  RT @WorldofAnimal1: üêæBeautiful Olive!!‚ù§\\n#dogs... 2020-10-20 17:27:57   \n",
       "1  RT @WorldofAnimal1: üêæMeet Gorgeous Sam!!üòÉ\\n#Ca... 2020-10-20 17:27:52   \n",
       "2  Injured \\n\\n#spooktober #digitalart #digitalil... 2020-10-20 17:19:35   \n",
       "3  This video gives a high-level introduction to ... 2020-10-20 17:15:03   \n",
       "4  RT @WilliamsRef: Take a look at our pharmacy c... 2020-10-20 17:12:00   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  rt beautiful olive dogsoftwitter doglover vete...  \n",
       "1  rt meet gorgeous sam catsontwitter catsoftwitt...  \n",
       "2  injured spooktober digitalart digitalillustrat...  \n",
       "3  this video gives a high level introduction to ...  \n",
       "4  rt take a look at our pharmacy coldroom with b...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"Data.xlsx\", inferSchema='')\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)', ' ', tweet).split())\n",
    "\n",
    "data['clean_tweet'] = df['Tweets'].apply(lambda x: clean_tweet(x).lower())\n",
    "data.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+\n",
      "|              Tweets|         tweet_date|         clean_tweet|\n",
      "+--------------------+-------------------+--------------------+\n",
      "|RT @WorldofAnimal...|2020-10-20 17:27:57|rt beautiful oliv...|\n",
      "|RT @WorldofAnimal...|2020-10-20 17:27:52|rt meet gorgeous ...|\n",
      "|Injured \n",
      "\n",
      "#spookt...|2020-10-20 17:19:35|injured spooktobe...|\n",
      "|This video gives ...|2020-10-20 17:15:03|this video gives ...|\n",
      "|RT @WilliamsRef: ...|2020-10-20 17:12:00|rt take a look at...|\n",
      "|RT @WorldofAnimal...|2020-10-20 17:08:17|rt beautiful oliv...|\n",
      "|RT @WorldofAnimal...|2020-10-20 17:08:12|rt meet gorgeous ...|\n",
      "|CM Inaugurates Su...|2020-10-20 17:08:00|cm inaugurates su...|\n",
      "|Don't miss our la...|2020-10-20 17:05:10|don t miss our la...|\n",
      "|RT @WorldofAnimal...|2020-10-20 17:02:28|rt meet gorgeous ...|\n",
      "|Emergicare specia...|2020-10-20 17:02:18|emergicare specia...|\n",
      "|Ride along with M...|2020-10-20 17:02:16|ride along with m...|\n",
      "|RT @WorldofAnimal...|2020-10-20 16:59:52|rt meet gorgeous ...|\n",
      "|@voitechnology yo...|2020-10-20 16:57:57|your new scooters...|\n",
      "|The same question...|2020-10-20 16:57:33|the same question...|\n",
      "|RT @WorldofAnimal...|2020-10-20 16:55:39|rt beautiful oliv...|\n",
      "|RT @WorldofAnimal...|2020-10-20 16:55:34|rt meet gorgeous ...|\n",
      "|üêæMeet Gorgeous S...|2020-10-20 16:54:49|meet gorgeous sam...|\n",
      "|RT @MFauver3: Lat...|2020-10-20 16:52:37|rt latest pricing...|\n",
      "|Almost 75% of #Ho...|2020-10-20 16:40:55|almost 75 of hosp...|\n",
      "+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.createDataFrame(data)\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting  the tweet column to list for tokenizing and generating sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = sdf.select(\"clean_tweet\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Bing Liu Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNotNull(value):\n",
    "    return value is not None and len(value)>0\n",
    "\n",
    "dict_pos = []\n",
    "dict_neg = []\n",
    "f = open('IDS 561/Assignemnt3/opinion_lexicon/negative-words.txt','r')\n",
    "for line in f:\n",
    "    t= line.strip().lower();\n",
    "    if (isNotNull(t)):\n",
    "        dict_neg.append(t)\n",
    "f.close()\n",
    "\n",
    "f = open('IDS 561/Assignemnt3/opinion_lexicon/positive-words.txt','r')\n",
    "for line in f:\n",
    "    t = line.strip().lower();\n",
    "    if (isNotNull(t)):\n",
    "        dict_pos.append(t)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign sentiment score from the Bing Liu lexicon to each tweet and store in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = []\n",
    "for i in range(sdf.count()):\n",
    "    tokens = nltk.word_tokenize(text[i])\n",
    "    neg_cnt = 0\n",
    "    pos_cnt = 0\n",
    "    for neg in dict_neg:\n",
    "        if (neg in tokens):\n",
    "            neg_cnt = neg_cnt +1\n",
    "    for pos in dict_pos:\n",
    "        if (pos in tokens):\n",
    "            pos_cnt = pos_cnt +1\n",
    "    sentiment_analysis.append(pos_cnt - neg_cnt)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and merging dataframe which includes the sentiment score and the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+-----+\n",
      "|              Tweets|         tweet_date|         clean_tweet|value|\n",
      "+--------------------+-------------------+--------------------+-----+\n",
      "|Surely Jonathan V...|2020-10-20 16:36:14|surely jonathan v...|    0|\n",
      "|COVID-19 Update: ...|2020-10-20 16:35:09|covid 19 update g...|    1|\n",
      "|Remaining HIPAA c...|2020-10-19 16:00:00|remaining hipaa c...|    2|\n",
      "|BEST of the WEEK:...|2020-10-18 11:00:35|best of the week ...|    1|\n",
      "|\"Luna in the Gard...|2020-10-20 15:20:00|luna in the garde...|    1|\n",
      "|Propofol sedation...|2020-10-20 11:07:02|propofol sedation...|    1|\n",
      "|The #healthcare i...|2020-10-19 19:03:52|the healthcare in...|    1|\n",
      "|RT @AFTER_MOUSE: ...|2020-10-19 12:58:18|rt mouse pong tou...|    1|\n",
      "|Time for Marketin...|2020-10-19 11:48:55|time for marketin...|    0|\n",
      "|RT @NewsRajwar: T...|2020-10-18 07:25:49|rt the adept team...|    0|\n",
      "|Congrats to Henle...|2020-10-20 09:30:48|congrats to henle...|    0|\n",
      "|RT @DrDMacaskill:...|2020-10-20 07:41:20|rt on worldosteop...|    0|\n",
      "|RT @BUMBLEance: T...|2020-10-20 06:21:27|rt the experience...|    1|\n",
      "|RT @HyperfineR: T...|2020-10-19 02:32:50|rt tomorrow 10 19...|    0|\n",
      "|Who will tackle #...|2020-10-18 13:14:06|who will tackle o...|   -1|\n",
      "|RT @NewsRajwar: T...|2020-10-17 22:04:07|rt the adept team...|    0|\n",
      "|RT @butterflyswim...|2020-10-17 20:09:47|rt 1 brain tumors...|   -2|\n",
      "|RT @ejmarkow: Vol...|2020-10-20 08:28:10|rt volunteers nee...|    0|\n",
      "|Improving #Cybers...|2020-10-20 07:15:25|improving cyberse...|    2|\n",
      "|RT @HyperfineR: T...|2020-10-19 22:15:19|rt tomorrow 10 19...|    0|\n",
      "+--------------------+-------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, StructType, StructField, LongType\n",
    "\n",
    "#create a dataframe for the sentiment score list\n",
    "df2 = spark.createDataFrame(sentiment_analysis, IntegerType())\n",
    "\n",
    "#merging the sentiment score dataframe with the original dataframe\n",
    "def with_column_index(sdf): \n",
    "    new_schema = StructType(sdf.schema.fields + [StructField(\"ColumnIndex\", LongType(), False),])\n",
    "    return sdf.rdd.zipWithIndex().map(lambda row: row[0] + (row[1],)).toDF(schema=new_schema)\n",
    "\n",
    "df1_ci = with_column_index(sdf)\n",
    "df2_ci = with_column_index(df2)\n",
    "df_joined = df1_ci.join(df2_ci, df1_ci.ColumnIndex == df2_ci.ColumnIndex, 'inner').drop(\"ColumnIndex\")\n",
    "df_joined.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting and renaming columns as per requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|       Tweet_content|Sentiment_Score|\n",
      "+--------------------+---------------+\n",
      "|Surely Jonathan V...|              0|\n",
      "|COVID-19 Update: ...|              1|\n",
      "|Remaining HIPAA c...|              2|\n",
      "|BEST of the WEEK:...|              1|\n",
      "|\"Luna in the Gard...|              1|\n",
      "|Propofol sedation...|              1|\n",
      "|The #healthcare i...|              1|\n",
      "|RT @AFTER_MOUSE: ...|              1|\n",
      "|Time for Marketin...|              0|\n",
      "|RT @NewsRajwar: T...|              0|\n",
      "|Congrats to Henle...|              0|\n",
      "|RT @DrDMacaskill:...|              0|\n",
      "|RT @BUMBLEance: T...|              1|\n",
      "|RT @HyperfineR: T...|              0|\n",
      "|Who will tackle #...|             -1|\n",
      "|RT @NewsRajwar: T...|              0|\n",
      "|RT @butterflyswim...|             -2|\n",
      "|RT @ejmarkow: Vol...|              0|\n",
      "|Improving #Cybers...|              2|\n",
      "|RT @HyperfineR: T...|              0|\n",
      "+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final = df_joined.select('Tweets', 'value')\n",
    "df_final = df_final.withColumnRenamed(\"Tweets\", \"Tweet_content\").withColumnRenamed(\"value\", \"Sentiment_Score\")\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to pandas dataframe and saving locally as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_content</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Surely Jonathan Van-Tam or #JVT as he's being ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Update: Global Electronic Health Reco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remaining HIPAA compliant is one of the top pr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BEST of the WEEK: North Wing extension of Rigs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Luna in the Garden\" \\nhttps://t.co/Z76wZkdk9V...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Tweet_content  Sentiment_Score\n",
       "0  Surely Jonathan Van-Tam or #JVT as he's being ...                0\n",
       "1  COVID-19 Update: Global Electronic Health Reco...                1\n",
       "2  Remaining HIPAA compliant is one of the top pr...                2\n",
       "3  BEST of the WEEK: North Wing extension of Rigs...                1\n",
       "4  \"Luna in the Garden\" \\nhttps://t.co/Z76wZkdk9V...                1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df = df_final.select(\"*\").toPandas()\n",
    "pandas_df.to_csv(r'final_output.csv', index = False, header=True)\n",
    "pandas_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
